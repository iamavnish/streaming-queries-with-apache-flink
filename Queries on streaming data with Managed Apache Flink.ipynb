{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries on streaming data with Managed Apache Flink\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "import os\n",
        "import json\n",
        "\n",
        "from datetime import datetime\n",
        "from pyflink.common import Row\n",
        "from pyflink.table.expressions import col, lit\n",
        "from pyflink.table import (EnvironmentSettings, StreamTableEnvironment, TableEnvironment, TableDescriptor, Schema,\n",
        "                           DataTypes, FormatDescriptor)\n",
        "from pyflink.datastream import StreamExecutionEnvironment\n",
        "from pyflink.table.window import Slide\n",
        "from pyflink.table.udf import udf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "First, set up the environment for executing table programs in streaming mode with the following lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "env_settings = EnvironmentSettings.in_streaming_mode()\n",
        "table_env = TableEnvironment.create(env_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " As an example, the data that you will ingest looks like this:\n",
        "\n",
        "```json\n",
        "{\n",
        "    'order_id': '1f4da8b2-73d0-49d5-9762-3e2e0a3cf004', \n",
        "    'order_timestamp': '2024-04-04T15:32:03', \n",
        "    'order_date': '2024-04-04', \n",
        "    'customer_number': 198, \n",
        "    'customer_visit_number': 1,\n",
        "    'customer_city': 'Makati City', \n",
        "    'customer_country': 'Philippines',\n",
        "    'customer_credit_limit': 60237,\n",
        "    'device_type': 'desktop', \n",
        "    'browser': 'Opera/9.32.(Windows 98; tig-ER) Presto/2.9.179 Version/10.00', \n",
        "    'operating_system': 'Android', \n",
        "    'product_code': 'S32_1268', \n",
        "    'product_line': 'Trucks and Buses',\n",
        "    'product_unitary_price': 96.31, \n",
        "    'quantity': 10, \n",
        "    'total_price': 963.1,\n",
        "    'traffic_source': 'www.hardin-green.com'\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "\n",
        "input_table_name = \"source_stream\"\n",
        "table_env.execute_sql(f\"DROP TABLE IF EXISTS {input_table_name};\")\n",
        "\n",
        "input_stream_name = \"kinesis-input-stream\"\n",
        "\n",
        "region=\"us-east-1\"\n",
        "source_table_ddl = \"\"\"\n",
        "  CREATE TABLE {0} (\n",
        "    order_id STRING,\n",
        "    order_timestamp TIMESTAMP(0),\n",
        "    order_date STRING,\n",
        "    customer_number INT,\n",
        "    customer_visit_number INT,\n",
        "    customer_city STRING,\n",
        "    customer_country STRING,\n",
        "    customer_credit_limit INT,\n",
        "    device_type STRING,\n",
        "    browser STRING,\n",
        "    operating_system STRING,\n",
        "    product_code STRING, \n",
        "    product_line STRING,\n",
        "    product_unitary_price NUMERIC,\n",
        "    quantity INT, \n",
        "    total_price NUMERIC,\n",
        "    traffic_source STRING,\n",
        "    WATERMARK FOR order_timestamp AS order_timestamp - INTERVAL '5' MINUTES)\n",
        "    PARTITIONED BY (order_id)\n",
        "    WITH (\n",
        "    'connector' = 'kinesis',\n",
        "    'stream' = '{1}',\n",
        "    'aws.region' = '{2}',\n",
        "    'format' = 'json',\n",
        "    'scan.stream.initpos' = 'TRIM_HORIZON',\n",
        "    'json.timestamp-format.standard' = 'ISO-8601'\n",
        "    ) \"\"\".format(input_table_name, input_stream_name, region)\n",
        "table_env.execute_sql(source_table_ddl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's create an User Defined Function (UDF) to convert the timestamps into string. This is helpful as a workaround to save timestamps in AWS Kinesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "@udf(input_types=[DataTypes.TIMESTAMP(3)], result_type=DataTypes.STRING())\n",
        "def to_string(i):\n",
        "    return str(i)\n",
        "table_env.create_temporary_system_function(\"to_string\", to_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "Now, you will create a sliding window table from your `source_stream`. Here you can use the sliding window query to get the total number of sales. \n",
        "In this case, define the window size to be of 6 minutes while the window slide to be of 3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "# Sliding window query\n",
        "input_table = table_env.from_path(\"source_stream\")\n",
        "sliding_window_table = (\n",
        "        input_table.window(\n",
        "            Slide.over(lit(6).minute)\n",
        "            .every(lit(3).minutes)\n",
        "            .on(col(\"order_timestamp\"))\n",
        "            .alias(\"six_minute_window\")\n",
        "        )\n",
        "        .group_by(col(\"six_minute_window\"))\n",
        "        .select(to_string(col(\"six_minute_window\").end).alias(\"event_time\"), col(\"total_price\").sum.alias(\"total_sales\"))\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a temporary view in your table environment based on the sliding window table that you created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "table_env.create_temporary_view(\"sliding_window_table\", sliding_window_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "In the next cell, you have to define the schema of your sink table, which will be actually one of the output AWS Kinesis data streams. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "\n",
        "table_name = \"output_sliding_sales_stream\"\n",
        "table_env.execute_sql(f\"DROP TABLE IF EXISTS {table_name};\")\n",
        "\n",
        "stream_name = \"kinesis-total-sales-slide-output-stream\"\n",
        "\n",
        "region=\"us-east-1\"\n",
        "source_table_ddl = \"\"\"\n",
        " CREATE TABLE {0} (\n",
        "    event_time STRING,\n",
        "    total_sales NUMERIC)\n",
        "\n",
        "    WITH (\n",
        "    'connector' = 'kinesis',\n",
        "    'stream' = '{1}',\n",
        "    'aws.region' = '{2}',\n",
        "    'format' = 'json',\n",
        "    'json.timestamp-format.standard' = 'ISO-8601'\n",
        "    ) \"\"\".format(table_name, stream_name, region)\n",
        "table_env.execute_sql(source_table_ddl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "After you have defined the schema in your output table, insert the data from the sliding window table into your sink:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%flink.pyflink\n",
        "table_result = table_env.execute_sql(\"INSERT INTO {0} SELECT * FROM {1}\"\n",
        "                                     .format(\"output_sliding_sales_stream\", \"sliding_window_table\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "Run the following commands to run the consumer script:\n",
        "\n",
        "```bash\n",
        "python3 scripts/consumer/src/consumer.py kinesis-total-sales-slide-output-stream\n",
        "```\n",
        "\n",
        "You should start seeing some processed records with the schema that you just generated and should look similar to this output:\n",
        "\n",
        "```json\n",
        "{'event_time': '2024-06-01 01:00:00', 'total_sales': 25385}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "python",
      "pygments_lexer": "scala",
      "version": "3.11.5"
    },
    "name": "Streaming Queries with Apache Flink - Solution"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
